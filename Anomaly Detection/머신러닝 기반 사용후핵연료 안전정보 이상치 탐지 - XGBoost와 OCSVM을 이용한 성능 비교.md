본 포스팅은 제가 읽었던 논문을 간단하게 정리하는 글입니다. 논문의 모든 내용을 작성하는 것이 아닌, 일부분만 담겨 있으므로 자세한 내용은 [원본 논문](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11440224)을 확인해 주시기를 바랍니다. 또한, 논문을 잘못 이해한 부분이 있을 수 있으므로, 양해 바랍니다.

---

![](https://velog.velcdn.com/images/kyyle/post/3644a596-f8e3-4b6f-9f10-1f91bf1ae6ae/image.png)


# 요약 
본 논문는 XGBoost 기반의 이상치 탐지를 소개함. 기존에 사용되어 온 OCSVM과의 비교를 통해 XGBoost의 성능을 비교 분석함.

# 서론
일반적인 산업 현장에서는 비정상 데이터보다 정상 데이터의 수가 훨씬 많음. 비정상 데이터 없이, 정상 데이터만으로 모델을 학습하여 이상 탐지를 수행하는 여러 방법이 존재함. 본 논문에서도 정상 데이터만으로 모델을 학습하여 이상치 탐지를 수행함.

XGBoost를 사용한 이상 탐지 방법은 오토인코더를 활용한 이상 탐지 방법과 유사함. 정상 데이터에 의해 학습된 XGBoost는 정상 데이터를 기반으로 특성 값을 예측할 때 실제 값과 유사한 값을 예측할 것임. 즉, 정상 데이터에 대해서는 작은 오차를 가지고, 비정상 데이터에 대해서는 큰 오차를 가질 것이며, 데이터의 오차가 설정한 임계값보다 크다면 그 데이터를 비정상(이상치)로 판단할 수 있음.

본 논문에서는 제안한 방법인 XGBoost의 이상치 탐지 성능을 검증하기 위해 이상치 탐지를 위한 고전적인 기계학습 방법인 OCSVM(One-Class Support Vector Machine)과 성능을 비교함. 이를 위해 가상의 데이터(사용후핵연료 데이터)를 사용하여 이상치 탐지를 수행함. 

# 품질관리를 위한 이상치 탐지 방법 제안

사용후핵연료 안전정보 품질관리를 위한 XGBoost 기반의 이상치 검출 방법은 다음과 같음.

1. 주요 특성의 개수를 $N$이라고 하면, 정상 데이터를 사용하여 $N$개의 XGBoost 모델을 훈련함. $i$번째 특성을 제외한 $N-1$개의 특성으로 모델을 훈련하여 $i$번째 특성을 예측하도록 함.
2. 훈련된 $N$개의 XGBoost에 새로운 데이터를 입력하여 각 모델마다 해당하는 특성 값 예측 
3. 예측된 데이터와 실제 데이터의 잔차를 계산
4. 잔차의 합이 임계값 이상일 때 비정상 데이터로 판별

본 논문에서는 훈련 데이터에 포함되지 않은 검증 데이터에 대한 잔차를 사용하여 임계값을 결정함. 계산된 잔차의 95% 신뢰구간 상한을 임계값으로 사용함. 


# 결론 

XGBoost는 정상적인 입력에서 높은 정확도를 보이며 정상적이지 않은 입력에서도 안정적인 예측값을 제공하여 정상치와 이상치를 구분하는 결과를 보여주었음. 반면에 상관관계를 이용하여 학습된 OCSVM은 정상적인 입력에서는 좋은 분류 성능을 보여줬으나, 학습 데이터와 차이가 크지 않은 비정상 입력에서는 정상 데이터로 분류하여 제대로 탐지하지 못하였음. 